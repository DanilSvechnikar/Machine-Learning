{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:40.273936900Z",
     "start_time": "2023-08-18T11:33:40.140962300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "from utils import init_random_seed, train_eval_loop_lstm, \\\n",
    "    get_params_number, train_eval_loop_attention\n",
    "from modelLSTM import Encoder, Decoder, Seq2Seq\n",
    "from modelAttention import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "init_random_seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:40.368937500Z",
     "start_time": "2023-08-18T11:33:40.257937300Z"
    }
   },
   "id": "943bbaa9b1db708f"
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "path_dataset = './Data/multi30k'\n",
    "\n",
    "spacy_ger = spacy.load('de_core_news_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:42.185787600Z",
     "start_time": "2023-08-18T11:33:40.369937Z"
    }
   },
   "id": "efc49f25ee853552"
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "def tokenizer_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text) if tok.text not in string.punctuation]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:42.297787600Z",
     "start_time": "2023-08-18T11:33:42.189788100Z"
    }
   },
   "id": "54161ea4febd4a58"
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [],
   "source": [
    "def tokenizer_eng(text):\n",
    "    return [tok.text for tok in  spacy_eng.tokenizer(text) if tok.text not in string.punctuation]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:42.409786500Z",
     "start_time": "2023-08-18T11:33:42.299788400Z"
    }
   },
   "id": "69ff8e34b9d8d634"
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenizer_ger, \n",
    "               lower=True,\n",
    "               init_token='<sos>',\n",
    "               eos_token='<eos>')\n",
    "\n",
    "english = Field(tokenize=tokenizer_eng,\n",
    "               lower=True,\n",
    "               init_token='<sos>',\n",
    "               eos_token='<eos>')\n",
    "\n",
    "fields = [('english', english), ('german', german)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:42.522788700Z",
     "start_time": "2023-08-18T11:33:42.411793Z"
    }
   },
   "id": "ab743f96f4e952f5"
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "    path=path_dataset,\n",
    "    train='train.csv',\n",
    "    validation='valid.csv',\n",
    "    test='test.csv',\n",
    "    format='csv',\n",
    "    fields=fields,\n",
    "    skip_header=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:47.298784900Z",
     "start_time": "2023-08-18T11:33:42.524789500Z"
    }
   },
   "id": "fb87d682fb048bbe"
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [
    {
     "data": {
      "text/plain": "(28000, 1000, 1000)"
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:47.411786200Z",
     "start_time": "2023-08-18T11:33:47.300786700Z"
    }
   },
   "id": "80bee062a423ea96"
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:47.708785600Z",
     "start_time": "2023-08-18T11:33:47.414789Z"
    }
   },
   "id": "408359cb67ad67ff"
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "(7665, 5757)"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(german.vocab), len(english.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:47.820797500Z",
     "start_time": "2023-08-18T11:33:47.712786700Z"
    }
   },
   "id": "21610b97c808599d"
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "load_model = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:47.929786Z",
     "start_time": "2023-08-18T11:33:47.822794700Z"
    }
   },
   "id": "5ac7412f9b7b2b94"
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "# save_path_model = '../../Pre-trained Models/Transformer(LSTM) For Translation.pth'\n",
    "# \n",
    "# num_epochs = 25\n",
    "# lr = 1.0e-3\n",
    "# batch_size = 128\n",
    "# early_stopping_patience = 5\n",
    "# scheduler_patience = 3\n",
    "# teacher_force_ratio = 0.3\n",
    "# \n",
    "# input_size_encoder = len(german.vocab)\n",
    "# input_size_decoder = len(english.vocab)\n",
    "# output_size = len(english.vocab)\n",
    "# encoder_embedding_size = 100\n",
    "# decoder_embedding_size = 100\n",
    "# hidden_size = 512\n",
    "# num_layers = 2\n",
    "# enc_dropout = 0.3\n",
    "# dec_dropout = 0.3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.040784900Z",
     "start_time": "2023-08-18T11:33:47.931789800Z"
    }
   },
   "id": "7f6e2021e490d554"
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [],
   "source": [
    "# encoder_net = Encoder(input_size_encoder,\n",
    "#                       encoder_embedding_size,\n",
    "#                       hidden_size,\n",
    "#                       num_layers,\n",
    "#                       enc_dropout).to(device)\n",
    "# \n",
    "# decoder_net = Decoder(input_size_decoder,\n",
    "#                       decoder_embedding_size,\n",
    "#                       hidden_size,\n",
    "#                       output_size,\n",
    "#                       num_layers,\n",
    "#                       dec_dropout).to(device)\n",
    "# \n",
    "# model = Seq2Seq(encoder_net, decoder_net, device, len(english.vocab)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.152785100Z",
     "start_time": "2023-08-18T11:33:48.041793400Z"
    }
   },
   "id": "85d7b281aa6b1bff"
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "save_path_model = './Pre-trained/Transformer(Attention) For Translation.pth'\n",
    "\n",
    "num_epochs = 15\n",
    "lr = 1.0e-3\n",
    "batch_size = 2\n",
    "early_stopping_patience = 3\n",
    "scheduler_patience = 2\n",
    "\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 128\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.1\n",
    "max_len = 40\n",
    "forward_expansion = 2048\n",
    "src_pad_idx = english.vocab.stoi['<pad>']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.265787700Z",
     "start_time": "2023-08-18T11:33:48.155798700Z"
    }
   },
   "id": "86a75e9fa8bdab5"
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device\n",
    ").to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.471785700Z",
     "start_time": "2023-08-18T11:33:48.267798900Z"
    }
   },
   "id": "7ed695014f96d15a"
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Transformer:\n\tsize mismatch for src_position_embedding.weight: copying a param with shape torch.Size([100, 128]) from checkpoint, the shape in current model is torch.Size([40, 128]).\n\tsize mismatch for trg_position_embedding.weight: copying a param with shape torch.Size([100, 128]) from checkpoint, the shape in current model is torch.Size([40, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[368], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m load_model:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43msave_path_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MLPython\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[1;34m(self, state_dict, strict)\u001B[0m\n\u001B[0;32m   2036\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[0;32m   2037\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2038\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(k) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[0;32m   2040\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 2041\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   2042\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[0;32m   2043\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for Transformer:\n\tsize mismatch for src_position_embedding.weight: copying a param with shape torch.Size([100, 128]) from checkpoint, the shape in current model is torch.Size([40, 128]).\n\tsize mismatch for trg_position_embedding.weight: copying a param with shape torch.Size([100, 128]) from checkpoint, the shape in current model is torch.Size([40, 128])."
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    model.load_state_dict(torch.load(save_path_model, map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.721801800Z",
     "start_time": "2023-08-18T11:33:48.472785600Z"
    }
   },
   "id": "9ca9eb5ca505297c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T11:33:48.724798500Z"
    }
   },
   "id": "f0e22159ee9b4fbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.732788900Z",
     "start_time": "2023-08-18T11:33:48.726788100Z"
    }
   },
   "id": "4f9d2f4aad965362"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       patience=scheduler_patience,\n",
    "                                                       verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T11:33:48.728787700Z"
    }
   },
   "id": "9aa8c3b20a41ec05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    sort=False,\n",
    "    device=device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-18T11:33:48.730788800Z"
    }
   },
   "id": "b8e7ed24f915f8b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_params_number(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:33:48.733792700Z",
     "start_time": "2023-08-18T11:33:48.733792700Z"
    }
   },
   "id": "eec03132368aa243"
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0 / 15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "tensor([[   2,    2],\n",
      "        [   4,    4],\n",
      "        [   8,    8],\n",
      "        [ 435, 1884],\n",
      "        [   4,    4],\n",
      "        [1082,   67],\n",
      "        [   8, 4807],\n",
      "        [  66, 1974],\n",
      "        [   4,   12],\n",
      "        [2089,   49],\n",
      "        [  26,  828],\n",
      "        [  80,    7],\n",
      "        [   8,    4],\n",
      "        [ 140,  304],\n",
      "        [   6,    3],\n",
      "        [3413,    1]], device='cuda:0')\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = train_eval_loop_attention(model,\n",
    "                                       train_iterator, valid_iterator,\n",
    "                                       optimizer, criterion,\n",
    "                                       num_epochs,\n",
    "                                       early_stopping_patience,\n",
    "                                       scheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T11:46:40.881360400Z",
     "start_time": "2023-08-18T11:46:38.903392200Z"
    }
   },
   "id": "6cf6fb750981d01c"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# best_model = train_eval_loop_lstm(model,\n",
    "#                                   train_iterator, valid_iterator,\n",
    "#                                   optimizer, criterion,\n",
    "#                                   num_epochs,\n",
    "#                                   early_stopping_patience,\n",
    "#                                   scheduler,\n",
    "#                                   teacher_force_ratio)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:07:44.051214600Z",
     "start_time": "2023-08-18T10:07:44.009199Z"
    }
   },
   "id": "904d5a5ba3be3a39"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(), save_path_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:07:44.060203600Z",
     "start_time": "2023-08-18T10:07:44.023201600Z"
    }
   },
   "id": "86dc163350060c29"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# best_model = train_eval_loop_attention(model,\n",
    "#                                        train_iterator, valid_iterator,\n",
    "#                                        optimizer, criterion,\n",
    "#                                        num_epochs,\n",
    "#                                        early_stopping_patience,\n",
    "#                                        scheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:07:44.061194200Z",
     "start_time": "2023-08-18T10:07:44.039204200Z"
    }
   },
   "id": "9ff54597ebdec128"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(), save_path_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:07:44.072203600Z",
     "start_time": "2023-08-18T10:07:44.055195600Z"
    }
   },
   "id": "c868c29333ddafad"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "#     \n",
    "#     # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "#     if type(sentence) == str:\n",
    "#         tokens = [tok.text.lower() for tok in spacy_ger.tokenizer(sentence) if tok.text not in string.punctuation]\n",
    "#     else:\n",
    "#         tokens = [token.lower() for token in sentence]\n",
    "# \n",
    "#     # Add <SOS> and <EOS> in beginning and end respectively\n",
    "#     tokens.insert(0, german.init_token)\n",
    "#     tokens.append(german.eos_token)\n",
    "# \n",
    "#     # Go through each german token and convert to an index\n",
    "#     text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "# \n",
    "#     # Convert to Tensor\n",
    "#     sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "# \n",
    "#     # Build encoder hidden, cell state\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         hidden, cell = model.encoder(sentence_tensor)\n",
    "#     \n",
    "#     outputs = [english.vocab.stoi['<sos>']]\n",
    "#     \n",
    "#     for _ in range(max_length):\n",
    "#         previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "#     \n",
    "#         with torch.no_grad():\n",
    "#             output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "#     \n",
    "#             best_guess = output.argmax(1).item()\n",
    "#     \n",
    "#         outputs.append(best_guess)\n",
    "#     \n",
    "#         # Model predicts it's the end of the sentence\n",
    "#         if outputs[-1] == english.vocab.stoi['<eos>']:\n",
    "#             break\n",
    "#     \n",
    "#     translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "#     \n",
    "#     return translated_sentence[1:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:07:44.094203600Z",
     "start_time": "2023-08-18T10:07:44.077198800Z"
    }
   },
   "id": "4719128bafa07ded"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [tok.text.lower() for tok in spacy_ger.tokenizer(sentence) if tok.text not in string.punctuation]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "    outputs = [english.vocab.stoi['<sos>']]\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "        \n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        \n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if outputs[-1] == english.vocab.stoi['<eos>']:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    return translated_sentence[1:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:38:01.054966200Z",
     "start_time": "2023-08-18T10:38:01.034957300Z"
    }
   },
   "id": "91c6045cd24a150f"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "sentence = 'Ein junges Mädchen schwimmt in einem Pool'\n",
    "\n",
    "trans_sent = translate_sentence(model, sentence,\n",
    "                                german, english,\n",
    "                                device, max_length=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:38:01.308506100Z",
     "start_time": "2023-08-18T10:38:01.197514900Z"
    }
   },
   "id": "4e511a0977ff47e8"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a young girl swimming in a pool\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(trans_sent))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:38:01.792804800Z",
     "start_time": "2023-08-18T10:38:01.783814100Z"
    }
   },
   "id": "21798bab789180d7"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    orig = []\n",
    "    \n",
    "    for example in data:\n",
    "        src = example.german\n",
    "        trg = example.english\n",
    "        \n",
    "        prediction = translate_sentence(model, src, \n",
    "                                        german, english, \n",
    "                                        device,\n",
    "                                        max_length=50)\n",
    "        \n",
    "        orig.append(src)\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "        \n",
    "    return bleu_score(outputs, targets), outputs, targets, orig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:19:01.426124900Z",
     "start_time": "2023-08-18T10:19:01.407129200Z"
    }
   },
   "id": "e63cc1bfeca0f2dd"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "bleu_num, outputs, targets, orig = bleu(test_data, model, german, english, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:20:35.778805800Z",
     "start_time": "2023-08-18T10:19:03.018244200Z"
    }
   },
   "id": "dede5160f4e6a75e"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Score: 35.25\n"
     ]
    }
   ],
   "source": [
    "print(f'Blue Score: {bleu_num*100:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:20:38.360492400Z",
     "start_time": "2023-08-18T10:20:38.327340500Z"
    }
   },
   "id": "9b5579ad0c7f506f"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tGerman text:\n",
      "ein mann mit einem orangefarbenen hut der etwas anstarrt\n",
      "ein mädchen an einer küste mit einem berg im hintergrund\n",
      "ein älterer mann spielt ein videospiel\n",
      "ein paar kinder sind im freien und spielen auf dem boden bei zwei bäumen\n",
      "asiatische frau trägt einen sonnenhut beim fahrradfahren\n",
      "\n",
      "\tEnglish text:\n",
      "a man in an orange hat starring at something\n",
      "a girl at the shore of a beach with a mountain in the distance\n",
      "an older man is playing a video arcade game\n",
      "some children are outside playing in the dirt where two trees are\n",
      "asian woman wearing a sunhat while riding a bike\n",
      "\n",
      "\tNeural text:\n",
      "a man in an orange hat <unk> something\n",
      "a girl on a shore with a mountain in the background\n",
      "an older man is playing a video game\n",
      "a few children are outside playing and playing on the floor near two trees\n",
      "asian woman carrying a sunhat around her fishing pole\n"
     ]
    }
   ],
   "source": [
    "num_example = 5\n",
    "\n",
    "print(\"\\tGerman text:\")\n",
    "for i in range(num_example):\n",
    "    print(' '.join(orig[-i]))\n",
    "    \n",
    "print()\n",
    "print(\"\\tEnglish text:\")\n",
    "for i in range(num_example):\n",
    "    print(' '.join(targets[-i][0]))\n",
    "    \n",
    "print()\n",
    "print(\"\\tNeural text:\")\n",
    "for i in range(num_example):\n",
    "    print(' '.join(outputs[-i]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T10:20:44.883974500Z",
     "start_time": "2023-08-18T10:20:44.847645900Z"
    }
   },
   "id": "47ec0c7e43a326e5"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T09:11:09.099278200Z",
     "start_time": "2023-08-17T09:11:09.075283700Z"
    }
   },
   "id": "7fce233f76320caf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
